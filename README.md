# Web Scraper

## Description
This project is a Control Line Interface web scraper app that allows users to input a URL and receive the scraped content as a file. It can scrape multiple pages and extract a wide range of elements such as CSS and HTML elements.

## Version

## Vision
The vision behind this project is to create an accessible means to scrape websites and save the information.

## Dependencies
- Node.js
- npm
- jsdom
- node-fetch
- standard

## Functional Requirements
1. URL input
    - The user can input a URL and recieve the scraped content

2. Elements
    - The Scraper extracts a wide range of HTML elements

3. Error Handling
    - The scraper should log erros and have error handling to deal with exceptions.

4. Results
    - Results are presented to the user as a file.

### Non Functional requirements
1. 

### License
This project is licensed under the MIT License

### Author 
Saskia Heinemann

